{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q-Learning_TicTacToe.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1s6r4hZ7GEQwC2eJJV3bR3nOm4hIYvPf5","authorship_tag":"ABX9TyNh9PbqENbbMqCmAEXpabRZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IkjCPj0nO_TD","colab_type":"code","colab":{}},"source":["import numpy as np\n","import random\n","from IPython.display import clear_output\n","\n","from statistics import mean\n","from random import randrange\n","from copy import deepcopy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pzbVwdZE-qY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a5b875e0-0b6f-4cdb-a38b-69ccfd4be5c1","executionInfo":{"status":"ok","timestamp":1588509689190,"user_tz":-120,"elapsed":771,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}}},"source":["Q = np.array([[0,0,0,0,0,0,0,0,0]])\n","S = np.array([[0,0,0,0,0,0,0,0,0]])\n","actual_state_index = 0\n","state_index_1 = 0\n","state_index_2 = 0 \n","state_index_3 = 0\n","action = 0\n","action_1 = 0\n","action_2 = 0\n","action_3 = 0\n","print_all = False\n","print_q = False\n","actual_state_vector = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n","my_path = \"/content/drive/My Drive/Colab Notebooks/Q-Learning/q-learning_titactoe/\"\n","np.seterr(divide='ignore', invalid='ignore')"],"execution_count":157,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'divide': 'ignore', 'invalid': 'ignore', 'over': 'warn', 'under': 'ignore'}"]},"metadata":{"tags":[]},"execution_count":157}]},{"cell_type":"code","metadata":{"id":"u5OewweKRstI","colab_type":"code","colab":{}},"source":["Win = np.array([0,0,0])\n","\n","gamma = 0.8\n","epsilon = 0.2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rNpy4kUlROy","colab_type":"code","colab":{}},"source":["def clear_game():\n","  global actual_state_index\n","  global state_index_1\n","  global state_index_2\n","  global state_index_3\n","  global action\n","  global actual_state_vector\n","\n","  actual_state_index = 0\n","  state_index_1 = 0\n","  state_index_2 = 0\n","  state_index_3 = 0\n","  action = 0\n","  actual_state_vector = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n","\n","def add_state(new_state, player_symbol):\n","  global S\n","  global Q\n","  global actual_state_index\n","  global state_index_1\n","  global state_index_2\n","  global state_index_3\n","  global actual_state_vector\n","\n","  state_index_3 = state_index_2\n","  state_index_2 = state_index_1\n","  state_index_1 = actual_state_index\n","\n","  index = np.where((S[:,0] == new_state[0]) \n","                  & (S[:,1] == new_state[1]) \n","                  & (S[:,2] == new_state[2]) \n","                  & (S[:,3] == new_state[3]) \n","                  & (S[:,4] == new_state[4]) \n","                  & (S[:,5] == new_state[5]) \n","                  & (S[:,6] == new_state[6]) \n","                  & (S[:,7] == new_state[7])\n","                  & (S[:,8] == new_state[8]))\n","\n","  if (len(index[0]) == 0):\n","    actual_state_index = len(S)\n","    actual_state_vector = new_state\n","    S = np.vstack([S, new_state])\n","    Q = np.vstack([Q, [0,0,0,0,0,0,0,0,0]])\n","  else:\n","    actual_state_index = index[0][0]\n","    actual_state_vector = S[index[0][0]].copy()\n","\n","def map(value):\n","  if (value == 1):\n","     return \"o\"\n","  elif (value == 2):\n","    return \"x\"\n","  else:\n","    return \" \"\n","\n","def drow_actual_state():\n","  print(map(actual_state_vector[0]) + \"|\" + map(actual_state_vector[1]) + \"|\" + map(actual_state_vector[2]) +\n","      \"\\n\" + map(actual_state_vector[3]) + \"|\" + map(actual_state_vector[4]) + \"|\" + map(actual_state_vector[5]) +\n","      \"\\n\" + map(actual_state_vector[6]) + \"|\" + map(actual_state_vector[7]) + \"|\" + map(actual_state_vector[8]) + \"\\n\")\n","\n","def get_vector_index(row, col):\n","  return (row-1)*3+col-1\n","\n","def make_move_row_col(player_symbol, row, col):\n","  action = get_vector_index(row,col)\n","  return make_move(player_symbol)\n","\n","def make_move(player_symbol):\n","  global action_3\n","  global action_2\n","  global action_1\n","\n","  if (actual_state_vector[action] == 0):\n","    action_3 = action_2\n","    action_2 = action_1\n","    action_1 = action\n","    actual_state_vector[action] = player_symbol\n","    add_state(actual_state_vector, player_symbol)\n","    return True\n","  else:\n","    print(\"Invalid action!\")\n","    return False\n","\n","def random_move(player_symbol):\n","  global action\n","\n","  avalible_actions = [i for i, j in enumerate(actual_state_vector) if j == 0]\n","  if (avalible_actions != []):\n","    action = random.choice(avalible_actions)\n","    make_move(player_symbol) \n","\n","def switch_player(player_symbol):\n","  if (player_symbol == 1):\n","    return 2\n","  else:\n","    return 1  \n","\n","def check_win(player_symbol):\n","  global action\n","  global actual_state_vector\n","\n","  best_action = -1\n","  avalible_actions = [i for i, j in enumerate(actual_state_vector) if j == 0]\n","  vector_to_return = actual_state_vector.copy()\n","\n","  win = False\n","  for a in avalible_actions:\n","    action = a\n","    actual_state_vector[a] = player_symbol\n","    if (check_win_player(player_symbol) == 1):\n","      win = True\n","      best_action = action\n","    actual_state_vector = vector_to_return.copy()\n","\n","  if (win == True):\n","    action = best_action  \n","\n","  return win  \n","\n","def check_win_lose(player_symbol):\n","  win = check_win(player_symbol)\n","  if (win == True):\n","    make_move(player_symbol)\n","    add_reward(player_symbol)\n","    return True\n","\n","  lose = check_win(switch_player(player_symbol))\n","  if (lose == True):\n","    make_move(player_symbol)\n","    add_reward(player_symbol)\n","    return True\n","\n","  return False  \n","\n","def q_move(player_symbol, learn):\n","  global action\n","\n","  avalible_actions = [i for i, j in enumerate(actual_state_vector) if j == 0]\n","\n","  if (avalible_actions != []):\n","    action = np.where(Q[actual_state_index] == np.amax(Q[actual_state_index,avalible_actions]))[0]\n","\n","    if (len(action) > 1):\n","      action = random.choice(list(set(avalible_actions).intersection(action)))\n","    \n","    if (str(type(action)) == \"<class 'numpy.ndarray'>\"): #czasami action zamiast być liczbą jest jedno elementową tablicą\n","      action = action[0]\n","\n","    make_move(player_symbol)\n","    add_reward(player_symbol)\n","\n","def add_reward(player_symbol):\n","    avalible_actions = [i for i, j in enumerate(S[state_index_3]) if j == 0]\n","    if (avalible_actions != []):\n","      reward = Q[state_index_3, action_3] + gamma * mean(Q[state_index_1,avalible_actions]) #funkcja nagrody\n","      Q[state_index_3, action_3] = reward #przypisanie nagrody do Q\n","\n","def set_reward_if_win(player_symbol):\n","  win = check_win_player(player_symbol)\n","  if (win == 1):\n","    Q[state_index_1][action] = 100\n","    Q[state_index_2][action_2] = -100\n","    Win[player_symbol] = Win[player_symbol] + 1\n","    if (print_all == True):\n","      print('player ' + str(player_symbol) + ' won!')\n","    return True\n","  elif (win == 2):\n","    Q[state_index_1][action] = 10\n","    Q[state_index_2][action_2] = 10\n","    Win[0] = Win[0] + 1\n","    if (print_all == True):\n","      print('Draw!')\n","    return True\n","  else:\n","    return False  \n","\n","def check_win_player(player):\n","  if (((actual_state_vector[0] == player) & (actual_state_vector[1] == player) & (actual_state_vector[2] == player)) |\n","      ((actual_state_vector[3] == player) & (actual_state_vector[4] == player) & (actual_state_vector[5] == player)) |\n","      ((actual_state_vector[6] == player) & (actual_state_vector[7] == player) & (actual_state_vector[8] == player)) |\n","      ((actual_state_vector[0] == player) & (actual_state_vector[3] == player) & (actual_state_vector[6] == player)) |\n","      ((actual_state_vector[1] == player) & (actual_state_vector[4] == player) & (actual_state_vector[7] == player)) |\n","      ((actual_state_vector[2] == player) & (actual_state_vector[5] == player) & (actual_state_vector[8] == player)) |\n","      ((actual_state_vector[0] == player) & (actual_state_vector[4] == player) & (actual_state_vector[8] == player)) |\n","      ((actual_state_vector[2] == player) & (actual_state_vector[4] == player) & (actual_state_vector[6] == player))):\n","    return 1\n","  elif (len(actual_state_vector[actual_state_vector == 0]) == 0):\n","    return 2\n","  else:\n","    return 3      \n","\n","def player_move(player_symbol):\n","  global action\n","\n","  valid_move = False\n","  while (valid_move == False):\n","    action = int(input())-1;\n","    valid_move = make_move(player_symbol)\n","\n","  add_reward(player_symbol)  \n","\n","  print('\\n')\n","  drow_actual_state()\n","  return set_reward_if_win(player_symbol) \n","\n","def random_computer_move(player_symbol, learn):\n","  random_move(player_symbol)\n","  if (print_all == True):\n","    drow_actual_state()\n","  return set_reward_if_win(player_symbol)      \n","\n","def q_computer_move(player_symbol, learn):\n","  if (check_win_lose(player_symbol) == False):\n","    if (random.uniform(0, 1) < epsilon):\n","      random_move(player_symbol)\n","    else:  \n","      q_move(player_symbol, learn)\n","\n","  if (print_all == True):\n","    drow_actual_state()\n","  return set_reward_if_win(player_symbol) \n","\n","def play_game(learn = False, learn_2 = False):\n","  global Q\n","\n","  clear_game()\n","  if (print_all == True):\n","    drow_actual_state()\n","  i = 0\n","  win = False\n","\n","  while win==False:\n","    if (print_q == True):\n","      print(Q[actual_state_index])\n","    i = i + 1\n","    if (i%2==1):\n","      if (learn == True):\n","        win = q_computer_move(1, learn)\n","      else:  \n","        win = player_move(1)\n","    else:  \n","      if (learn_2 == True):\n","        win = q_computer_move(2, learn)\n","      else:\n","        win = player_move(2)\n","\n","  if (np.amax(Q) >= 100):\n","    Q = Q / np.amax(Q) * 100\n","\n","def play_with_computer():\n","  global print_all\n","\n","  print_all = True\n","  play_game(False, True)\n","\n","def learn():\n","  global print_all\n","\n","  print_all = False\n","  for i in range(100000):\n","    if (i%10000==0):\n","      print(Win)\n","      print(Win / sum(Win))\n","      print(i)\n","    play_game(True, True)\n","\n","  print(Win)\n","  print(Win / sum(Win))\n","  print(\"finish\")  \n","\n","def Save(name = \"\"):\n","  np.savetxt(my_path + \"Q_\" + name + \".csv\", Q, delimiter=\",\")\n","  np.savetxt(my_path + \"S_\" + name + \".csv\", S, delimiter=\",\")\n","\n","def Load(name = \"\"):\n","  global Q\n","  global S\n","\n","  Q = np.genfromtxt(my_path + \"Q_\" + name + \".csv\", delimiter=',')\n","  S = np.genfromtxt(my_path + \"S_\" + name + \".csv\", delimiter=',')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKIZg-dllD8w","colab_type":"code","outputId":"18ce6774-16bf-40d0-a9a0-0b51bcdbaf8e","executionInfo":{"status":"ok","timestamp":1588509969425,"user_tz":-120,"elapsed":279084,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["learn()"],"execution_count":160,"outputs":[{"output_type":"stream","text":["[0 0 0]\n","[nan nan nan]\n","0\n","[8444 1013  543]\n","[0.8444 0.1013 0.0543]\n","10000\n","[17150  1911   939]\n","[0.8575  0.09555 0.04695]\n","20000\n","[25892  2774  1334]\n","[0.86306667 0.09246667 0.04446667]\n","30000\n","[34878  3499  1623]\n","[0.87195  0.087475 0.040575]\n","40000\n","[44064  4102  1834]\n","[0.88128 0.08204 0.03668]\n","50000\n","[53251  4679  2070]\n","[0.88751667 0.07798333 0.0345    ]\n","60000\n","[62396  5263  2341]\n","[0.89137143 0.07518571 0.03344286]\n","70000\n","[71746  5680  2574]\n","[0.896825 0.071    0.032175]\n","80000\n","[80966  6234  2800]\n","[0.89962222 0.06926667 0.03111111]\n","90000\n","[90323  6675  3002]\n","[0.90323 0.06675 0.03002]\n","finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ScoOIVEfhHqg","colab_type":"code","outputId":"fb1fe76a-d801-434b-862d-dd88febb9643","executionInfo":{"status":"ok","timestamp":1588510125857,"user_tz":-120,"elapsed":34870,"user":{"displayName":"Konrad","photoUrl":"","userId":"17954070993580668211"}},"colab":{"base_uri":"https://localhost:8080/","height":969}},"source":["play_with_computer()"],"execution_count":161,"outputs":[{"output_type":"stream","text":[" | | \n"," | | \n"," | | \n","\n","5\n","\n","\n"," | | \n"," |o| \n"," | | \n","\n"," | | \n"," |o| \n"," | |x\n","\n","3\n","\n","\n"," | |o\n"," |o| \n"," | |x\n","\n"," | |o\n"," |o| \n","x| |x\n","\n","8\n","\n","\n"," | |o\n"," |o| \n","x|o|x\n","\n"," |x|o\n"," |o| \n","x|o|x\n","\n","1\n","\n","\n","o|x|o\n"," |o| \n","x|o|x\n","\n","o|x|o\n"," |o|x\n","x|o|x\n","\n","4\n","\n","\n","o|x|o\n","o|o|x\n","x|o|x\n","\n","Draw!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Day1Sa8LOqtR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}